# Movies-ETL
MOD 8 - ETL

Overview

The purpose of this challenge was to follow the ETL (extract, Transform, Load)  process to prepare large datasets for analyzing.
The steps for ETL are as follows:

Extract data from Wikipedia and Kaggle.
Transform the datasets via function data cleaning and mergining.
Upload the dataframes to the the final cleaned dataset into a SQL database

We were to create an automated pipeline that takes in new data, performs the appropriate transformations, and loads the data into existing tables. Once the SQL database is created, Amazing Prime wants us to create an automated pipeline that takes in new data, performs the appropriate transformations, and loads the data into existing tables. This will allow for easy iterations of the data for future use.
